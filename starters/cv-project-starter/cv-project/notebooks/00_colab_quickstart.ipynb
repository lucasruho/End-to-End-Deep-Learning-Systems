{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CV Starter — Colab/Kaggle Quickstart\n",
    "\n",
    "> Author : Badr TAJINI\n",
    "\n",
    "**Academic year:** 2025–2026  \n",
    "**School:** ECE  \n",
    "**Course:** Machine Learning & Deep Learning 2 \n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "Welcome! This notebook is intentionally beginner-friendly. Follow the steps exactly and you will confirm that the starter project works on a free GPU runtime.\n",
    "\n",
    "### Before you run anything\n",
    "1. **Open the notebook in Google Colab or Kaggle.**\n",
    "2. **Change the hardware accelerator to GPU (T4 preferred).**\n",
    "   * Colab: `Runtime` → `Change runtime type` → Hardware accelerator `GPU` → Save.\n",
    "   * Kaggle: `Settings` (gear icon) → Turn on `Accelerator` → Choose `T4 x1`.\n",
    "3. Once the GPU is enabled, run the cells **from top to bottom**. Every code cell has comments explaining what it does.\n",
    "\n",
    "The notebook will: (a) check that a GPU is available, (b) install dependencies, (c) run a quick smoke test that loads CIFAR-10 and performs one training step, and (d) show you how to launch the full training/evaluation commands when you are ready for longer experiments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Project files\n",
    "\n",
    "- Option A: `git clone <your_repo_url> cv-project`\n",
    "- Option B: Upload the `cv-project` folder via the left sidebar (ensure the root is `/content/cv-project`).\n",
    "\n",
    "Run the cell below afterwards; it will raise a helpful error if the folder is missing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick checklist before running code\n",
    "\n",
    "- **Colab:** Go to `Runtime → Change runtime type`, pick `GPU`, and click **Save**.\n",
    "- **Kaggle:** Open the gear icon in the top-right, enable **Accelerator**, and choose `T4 x1`.\n",
    "- Wait for the runtime to restart (Colab shows `Connected` again).\n",
    "- Then run every cell in order. If you see an error, stop, read the message, and re-run the cell after fixing the issue.\n",
    "\n",
    "Once the smoke test succeeds you can run the full training and evaluation commands shown at the end of the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69e3946",
   "metadata": {},
   "source": [
    "### How to run a cell\n",
    "- Click the little ▶️ button on the left of a cell, or press **Shift + Enter** (Colab) / **Ctrl + Enter** (Kaggle).\n",
    "- Wait for the cell to finish (a number like `[1]` appears once it is done).\n",
    "- If a cell shows an error, read the message, fix the issue, and re-run that same cell before moving forward.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b435543",
   "metadata": {},
   "source": [
    "### Step 0 — Confirm the GPU is ready\n",
    "Run the next cell. You should see a table with GPU details (name + memory).\n",
    "If you get the message `nvidia-smi unavailable`, the runtime is still on CPU—go back to the checklist above and switch it to GPU, then rerun the cell.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f1e4189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Nov 14 15:54:45 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 577.03                 Driver Version: 577.03         CUDA Version: 12.9     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                  Driver-Model | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4060 ...  WDDM  |   00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   61C    P0             20W /   50W |    7438MiB /   8188MiB |    100%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A           18076    C+G   ...Browser\\Application\\brave.exe      N/A      |\n",
      "|    0   N/A  N/A           31676      C   ...3\\envs\\pytorch_gpu\\python.exe      N/A      |\n",
      "|    0   N/A  N/A           36896      C   ...3\\envs\\pytorch_gpu\\python.exe      N/A      |\n",
      "|    0   N/A  N/A           38100      C   ...3\\envs\\pytorch_gpu\\python.exe      N/A      |\n",
      "|    0   N/A  N/A           44824      C   ...3\\envs\\pytorch_gpu\\python.exe      N/A      |\n",
      "|    0   N/A  N/A           45164    C+G   ...Browser\\Application\\brave.exe      N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi || echo \"nvidia-smi unavailable (CPU runtime)\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b72df6f",
   "metadata": {},
   "source": [
    "### Step 1 — Point the notebook at the project folder\n",
    "This cell makes sure Colab/Kaggle is looking at the `cv-project` directory.\n",
    "If it raises a `FileNotFoundError`, you likely uploaded the folder to a different place. Use the file browser on the left to confirm the path, fix it, and rerun the cell.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6ee2351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: C:\\Users\\lucas\\End-to-End-Deep-Learning-Systems\\End-to-End-Deep-Learning-Systems\\starters\\cv-project-starter\\cv-project\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "PROJECT_ROOT = Path.cwd().resolve()\n",
    "if PROJECT_ROOT.name == \"notebooks\":\n",
    "    PROJECT_ROOT = PROJECT_ROOT.parent.resolve()\n",
    "elif PROJECT_ROOT.name == \"content\":\n",
    "    candidate = PROJECT_ROOT / \"cv-project\"\n",
    "    if candidate.exists():\n",
    "        PROJECT_ROOT = candidate.resolve()\n",
    "\n",
    "if not (PROJECT_ROOT / \"src\").exists():\n",
    "    raise FileNotFoundError(\n",
    "        f\"Could not locate project root at {PROJECT_ROOT}. Clone or upload cv-project before proceeding.\"\n",
    "    )\n",
    "\n",
    "os.chdir(PROJECT_ROOT)\n",
    "if str(PROJECT_ROOT / \"src\") not in sys.path:\n",
    "    sys.path.append(str(PROJECT_ROOT / \"src\"))\n",
    "print(f\"Project root: {PROJECT_ROOT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "258db80c",
   "metadata": {},
   "source": [
    "### Step 2 — Install the project requirements\n",
    "This command reads `requirements.txt` and installs exactly the same packages you would get locally.\n",
    "Expect a lot of text output; that is normal. If installation fails, run the cell again before moving forward.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ed260df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\lucas\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from -r requirements.txt (line 1)) (2.5.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\lucas\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from -r requirements.txt (line 2)) (0.20.1)\n",
      "Requirement already satisfied: torchmetrics==1.4.0 in c:\\users\\lucas\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from -r requirements.txt (line 3)) (1.4.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\lucas\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from -r requirements.txt (line 4)) (6.0.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\lucas\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from -r requirements.txt (line 5)) (4.67.1)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\lucas\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from -r requirements.txt (line 6)) (3.10.6)\n",
      "Requirement already satisfied: seaborn in c:\\users\\lucas\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from -r requirements.txt (line 7)) (0.13.2)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\lucas\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from -r requirements.txt (line 8)) (1.7.2)\n",
      "Requirement already satisfied: numpy>1.20.0 in c:\\users\\lucas\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from torchmetrics==1.4.0->-r requirements.txt (line 3)) (2.0.1)\n",
      "Requirement already satisfied: packaging>17.1 in c:\\users\\lucas\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from torchmetrics==1.4.0->-r requirements.txt (line 3)) (25.0)\n",
      "Requirement already satisfied: lightning-utilities>=0.8.0 in c:\\users\\lucas\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from torchmetrics==1.4.0->-r requirements.txt (line 3)) (0.15.2)\n",
      "Requirement already satisfied: pretty-errors==1.2.25 in c:\\users\\lucas\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from torchmetrics==1.4.0->-r requirements.txt (line 3)) (1.2.25)\n",
      "Requirement already satisfied: colorama in c:\\users\\lucas\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from pretty-errors==1.2.25->torchmetrics==1.4.0->-r requirements.txt (line 3)) (0.4.6)\n",
      "Requirement already satisfied: filelock in c:\\users\\lucas\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from torch->-r requirements.txt (line 1)) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\lucas\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from torch->-r requirements.txt (line 1)) (4.15.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\lucas\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from torch->-r requirements.txt (line 1)) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\lucas\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from torch->-r requirements.txt (line 1)) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\lucas\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from torch->-r requirements.txt (line 1)) (2025.9.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\lucas\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from torch->-r requirements.txt (line 1)) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\lucas\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from sympy==1.13.1->torch->-r requirements.txt (line 1)) (1.3.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\lucas\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from torchvision->-r requirements.txt (line 2)) (11.1.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\lucas\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from matplotlib->-r requirements.txt (line 6)) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\lucas\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from matplotlib->-r requirements.txt (line 6)) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\lucas\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from matplotlib->-r requirements.txt (line 6)) (4.59.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\lucas\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from matplotlib->-r requirements.txt (line 6)) (1.4.8)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\lucas\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from matplotlib->-r requirements.txt (line 6)) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\lucas\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from matplotlib->-r requirements.txt (line 6)) (2.9.0.post0)\n",
      "Requirement already satisfied: pandas>=1.2 in c:\\users\\lucas\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from seaborn->-r requirements.txt (line 7)) (2.3.3)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\lucas\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from scikit-learn->-r requirements.txt (line 8)) (1.15.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\lucas\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from scikit-learn->-r requirements.txt (line 8)) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\lucas\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from scikit-learn->-r requirements.txt (line 8)) (3.6.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\lucas\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from lightning-utilities>=0.8.0->torchmetrics==1.4.0->-r requirements.txt (line 3)) (78.1.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\lucas\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from pandas>=1.2->seaborn->-r requirements.txt (line 7)) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\lucas\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from pandas>=1.2->seaborn->-r requirements.txt (line 7)) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\lucas\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->-r requirements.txt (line 6)) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\lucas\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from jinja2->torch->-r requirements.txt (line 1)) (3.0.2)\n"
     ]
    }
   ],
   "source": [
    "# Install project dependencies listed in requirements.txt\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab4562c",
   "metadata": {},
   "source": [
    "### Step 3 — Run the smoke test\n",
    "This quick check downloads CIFAR-10 (if needed), runs one mini-batch through the model, and saves `outputs/smoke_metrics.json`.\n",
    "You should see a short JSON output such as `{\"loss\": ..., \"batch_size\": 64, ...}`.\n",
    "If you hit a download or network error, wait a few seconds and re-run the cell; Colab sometimes needs a second try.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f4fa6b73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "{\n",
      "  \"loss\": 2.648414134979248,\n",
      "  \"batch_size\": 64,\n",
      "  \"num_classes\": 10,\n",
      "  \"device\": \"cuda\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from src import smoke_check\n",
    "\n",
    "smoke_path = smoke_check.run_smoke(\"configs/cv_cifar10_fast.yaml\")\n",
    "print(smoke_path.read_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4e2b4e",
   "metadata": {},
   "source": [
    "> **Why run the smoke test?**\n",
    "\n",
    "> The smoke test is a safety check before long training. It loads CIFAR‑10, runs a single forward/backward pass, and writes outputs/smoke_metrics.json. If this succeeds, you know:\n",
    "\n",
    "> - the dataset can be downloaded/read,\n",
    "> - the model compiles and runs on your GPU,\n",
    "> - dependencies are installed correctly.\n",
    ">\n",
    "> In short, if it fails, fix the error (missing folder, bad install, no GPU) before investing time in a full training run :\n",
    ">\n",
    "> *After !python src/evaluate.py ... (Step 4 below)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb93d07",
   "metadata": {},
   "source": [
    "## 1. Review smoke-test output\n",
    "- Confirm the previous cell printed a JSON block (loss, batch size, device).\n",
    "- You should now see `outputs/smoke_metrics.json` in the file browser on the left.\n",
    "- Need only a quick check? You can stop here. Ready for real training? Continue to Section 2 below.\n",
    "- If anything failed, read the error message carefully, fix the issue, and re-run the smoke cell before moving on.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea2d8ec",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4f22207e",
   "metadata": {},
   "source": [
    "## 2. Full training run (optional)\n",
    "Only run these cells when you want the complete experiment. On the first run PyTorch will also download CIFAR-10, so the first epoch may start slowly.\n",
    "\n",
    "**Before running:**\n",
    "1. Open `configs/cv_cifar10.yaml` (Menu → File → Open …) if you want to change hyperparameters.\n",
    "2. Ensure the runtime still shows a GPU connection.\n",
    "3. Close other browser tabs or notebooks to avoid memory pressure.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7b4a6f4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "# Train the model using the main configuration file. Expect visible progress bars.\n",
    "# The first time you run this it will also download CIFAR-10, so the progress bar\n",
    "# might pause around 0% while data is fetched.\n",
    "!python src/train.py --config configs/cv_cifar10.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "484af641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Accuracy: 0.9412. Saved eval.json, per_class_metrics.csv, confusion_matrix.png, and leaderboard.png in outputs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lucas\\End-to-End-Deep-Learning-Systems\\End-to-End-Deep-Learning-Systems\\starters\\cv-project-starter\\cv-project\\src\\evaluate.py:43: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(ckpt_path, map_location=device))\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the best checkpoint produced during training.\n",
    "# This will print accuracy and write the metrics/plots listed below.\n",
    "!python src/evaluate.py --config configs/cv_cifar10.yaml --ckpt outputs/best.pt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d4d59a",
   "metadata": {},
   "source": [
    "### Step 4 — What should I see now?\n",
    "- `outputs/best.pt`: saved checkpoint.\n",
    "- `outputs/log.csv`: training history (loss/accuracy per epoch).\n",
    "- `outputs/eval.json`, `per_class_metrics.csv`, `confusion_matrix.png`, `leaderboard.png`: evaluation artefacts.\n",
    "\n",
    "If any of these files are missing, scroll up for errors in the training/evaluation cells.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Mirror this workflow for other tracks\n",
    "\n",
    "1. Duplicate this notebook and rename it (e.g., `00_nlp_quickstart.ipynb`).\n",
    "2. Copy the corresponding starter folder into your Colab/Kaggle workspace (`nlp-project`, `od-project`, `ts-project`).\n",
    "3. Update the install cell so it matches that starter's `requirements.txt`.\n",
    "4. Replace `from src import smoke_check` with the helper module provided in the new starter (each repo ships with one).\n",
    "5. Point the train/eval commands at the new `configs/*.yaml` file.\n",
    "6. Optionally tweak the markdown text so instructions mention the right dataset and metrics.\n",
    "\n",
    "By following the same structure—GPU check → install → smoke test → full run—students can master all four tracks with a consistent workflow."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
