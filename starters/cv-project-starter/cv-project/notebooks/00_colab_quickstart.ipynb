{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CV Starter — Colab/Kaggle Quickstart\n",
    "\n",
    "> Author : Badr TAJINI\n",
    "\n",
    "**Academic year:** 2025–2026  \n",
    "**School:** ECE  \n",
    "**Course:** Machine Learning & Deep Learning 2 \n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "Welcome! This notebook is intentionally beginner-friendly. Follow the steps exactly and you will confirm that the starter project works on a free GPU runtime.\n",
    "\n",
    "### Before you run anything\n",
    "1. **Open the notebook in Google Colab or Kaggle.**\n",
    "2. **Change the hardware accelerator to GPU (T4 preferred).**\n",
    "   * Colab: `Runtime` → `Change runtime type` → Hardware accelerator `GPU` → Save.\n",
    "   * Kaggle: `Settings` (gear icon) → Turn on `Accelerator` → Choose `T4 x1`.\n",
    "3. Once the GPU is enabled, run the cells **from top to bottom**. Every code cell has comments explaining what it does.\n",
    "\n",
    "The notebook will: (a) check that a GPU is available, (b) install dependencies, (c) run a quick smoke test that loads CIFAR-10 and performs one training step, and (d) show you how to launch the full training/evaluation commands when you are ready for longer experiments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Project files\n",
    "\n",
    "- Option A: `git clone <your_repo_url> cv-project`\n",
    "- Option B: Upload the `cv-project` folder via the left sidebar (ensure the root is `/content/cv-project`).\n",
    "\n",
    "Run the cell below afterwards; it will raise a helpful error if the folder is missing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick checklist before running code\n",
    "\n",
    "- **Colab:** Go to `Runtime → Change runtime type`, pick `GPU`, and click **Save**.\n",
    "- **Kaggle:** Open the gear icon in the top-right, enable **Accelerator**, and choose `T4 x1`.\n",
    "- Wait for the runtime to restart (Colab shows `Connected` again).\n",
    "- Then run every cell in order. If you see an error, stop, read the message, and re-run the cell after fixing the issue.\n",
    "\n",
    "Once the smoke test succeeds you can run the full training and evaluation commands shown at the end of the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69e3946",
   "metadata": {},
   "source": [
    "### How to run a cell\n",
    "- Click the little ▶️ button on the left of a cell, or press **Shift + Enter** (Colab) / **Ctrl + Enter** (Kaggle).\n",
    "- Wait for the cell to finish (a number like `[1]` appears once it is done).\n",
    "- If a cell shows an error, read the message, fix the issue, and re-run that same cell before moving forward.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b435543",
   "metadata": {},
   "source": [
    "### Step 0 — Confirm the GPU is ready\n",
    "Run the next cell. You should see a table with GPU details (name + memory).\n",
    "If you get the message `nvidia-smi unavailable`, the runtime is still on CPU—go back to the checklist above and switch it to GPU, then rerun the cell.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1e4189",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi || echo \"nvidia-smi unavailable (CPU runtime)\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b72df6f",
   "metadata": {},
   "source": [
    "### Step 1 — Point the notebook at the project folder\n",
    "This cell makes sure Colab/Kaggle is looking at the `cv-project` directory.\n",
    "If it raises a `FileNotFoundError`, you likely uploaded the folder to a different place. Use the file browser on the left to confirm the path, fix it, and rerun the cell.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ee2351",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "PROJECT_ROOT = Path.cwd().resolve()\n",
    "if PROJECT_ROOT.name == \"notebooks\":\n",
    "    PROJECT_ROOT = PROJECT_ROOT.parent.resolve()\n",
    "elif PROJECT_ROOT.name == \"content\":\n",
    "    candidate = PROJECT_ROOT / \"cv-project\"\n",
    "    if candidate.exists():\n",
    "        PROJECT_ROOT = candidate.resolve()\n",
    "\n",
    "if not (PROJECT_ROOT / \"src\").exists():\n",
    "    raise FileNotFoundError(\n",
    "        f\"Could not locate project root at {PROJECT_ROOT}. Clone or upload cv-project before proceeding.\"\n",
    "    )\n",
    "\n",
    "os.chdir(PROJECT_ROOT)\n",
    "if str(PROJECT_ROOT / \"src\") not in sys.path:\n",
    "    sys.path.append(str(PROJECT_ROOT / \"src\"))\n",
    "print(f\"Project root: {PROJECT_ROOT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "258db80c",
   "metadata": {},
   "source": [
    "### Step 2 — Install the project requirements\n",
    "This command reads `requirements.txt` and installs exactly the same packages you would get locally.\n",
    "Expect a lot of text output; that is normal. If installation fails, run the cell again before moving forward.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed260df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install project dependencies listed in requirements.txt\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab4562c",
   "metadata": {},
   "source": [
    "### Step 3 — Run the smoke test\n",
    "This quick check downloads CIFAR-10 (if needed), runs one mini-batch through the model, and saves `outputs/smoke_metrics.json`.\n",
    "You should see a short JSON output such as `{\"loss\": ..., \"batch_size\": 64, ...}`.\n",
    "If you hit a download or network error, wait a few seconds and re-run the cell; Colab sometimes needs a second try.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4fa6b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import smoke_check\n",
    "\n",
    "smoke_path = smoke_check.run_smoke(\"configs/cv_cifar10_fast.yaml\")\n",
    "print(smoke_path.read_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4e2b4e",
   "metadata": {},
   "source": [
    "> **Why run the smoke test?**\n",
    "\n",
    "> The smoke test is a safety check before long training. It loads CIFAR‑10, runs a single forward/backward pass, and writes outputs/smoke_metrics.json. If this succeeds, you know:\n",
    "\n",
    "> - the dataset can be downloaded/read,\n",
    "> - the model compiles and runs on your GPU,\n",
    "> - dependencies are installed correctly.\n",
    ">\n",
    "> In short, if it fails, fix the error (missing folder, bad install, no GPU) before investing time in a full training run :\n",
    ">\n",
    "> *After !python src/evaluate.py ... (Step 4 below)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb93d07",
   "metadata": {},
   "source": [
    "## 1. Review smoke-test output\n",
    "- Confirm the previous cell printed a JSON block (loss, batch size, device).\n",
    "- You should now see `outputs/smoke_metrics.json` in the file browser on the left.\n",
    "- Need only a quick check? You can stop here. Ready for real training? Continue to Section 2 below.\n",
    "- If anything failed, read the error message carefully, fix the issue, and re-run the smoke cell before moving on.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f22207e",
   "metadata": {},
   "source": [
    "## 2. Full training run (optional)\n",
    "Only run these cells when you want the complete experiment. On the first run PyTorch will also download CIFAR-10, so the first epoch may start slowly.\n",
    "\n",
    "**Before running:**\n",
    "1. Open `configs/cv_cifar10.yaml` (Menu → File → Open …) if you want to change hyperparameters.\n",
    "2. Ensure the runtime still shows a GPU connection.\n",
    "3. Close other browser tabs or notebooks to avoid memory pressure.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4a6f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model using the main configuration file. Expect visible progress bars.\n",
    "# The first time you run this it will also download CIFAR-10, so the progress bar\n",
    "# might pause around 0% while data is fetched.\n",
    "!python src/train.py --config configs/cv_cifar10.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484af641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the best checkpoint produced during training.\n",
    "# This will print accuracy and write the metrics/plots listed below.\n",
    "!python src/evaluate.py --config configs/cv_cifar10.yaml --ckpt outputs/best.pt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d4d59a",
   "metadata": {},
   "source": [
    "### Step 4 — What should I see now?\n",
    "- `outputs/best.pt`: saved checkpoint.\n",
    "- `outputs/log.csv`: training history (loss/accuracy per epoch).\n",
    "- `outputs/eval.json`, `per_class_metrics.csv`, `confusion_matrix.png`, `leaderboard.png`: evaluation artefacts.\n",
    "\n",
    "If any of these files are missing, scroll up for errors in the training/evaluation cells.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Mirror this workflow for other tracks\n",
    "\n",
    "1. Duplicate this notebook and rename it (e.g., `00_nlp_quickstart.ipynb`).\n",
    "2. Copy the corresponding starter folder into your Colab/Kaggle workspace (`nlp-project`, `od-project`, `ts-project`).\n",
    "3. Update the install cell so it matches that starter's `requirements.txt`.\n",
    "4. Replace `from src import smoke_check` with the helper module provided in the new starter (each repo ships with one).\n",
    "5. Point the train/eval commands at the new `configs/*.yaml` file.\n",
    "6. Optionally tweak the markdown text so instructions mention the right dataset and metrics.\n",
    "\n",
    "By following the same structure—GPU check → install → smoke test → full run—students can master all four tracks with a consistent workflow."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
