{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Starter — Colab/Kaggle Quickstart \n",
    "\n",
    "> Author : Badr TAJINI\n",
    "\n",
    "**Academic year:** 2025–2026  \n",
    "**School:** ECE  \n",
    "**Course:** Machine Learning & Deep Learning 2 \n",
    "\n",
    "---\n",
    "\n",
    "Use this notebook to verify the tabular/time-series regression starter on a GPU runtime. It walks you through environment checks, dependency install, a smoke test, and optional full training/evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Project files\n",
    "\n",
    "- Option A: `git clone <your_repo_url> ts-project`\n",
    "- Option B: Upload the `ts-project` folder via the sidebar (`/content/ts-project` in Colab).\n",
    "\n",
    "Run the remaining cells afterwards; they will alert you if the folder is missing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick checklist before running code\n",
    "- Switch the runtime to **GPU (T4)** first.\n",
    "  - Colab: `Runtime → Change runtime type → GPU → Save`.\n",
    "  - Kaggle: gear icon → enable **Accelerator**, choose `T4 x1`.\n",
    "- Wait for the GPU session to reconnect.\n",
    "- Execute cells from top to bottom. Fix and rerun a cell if it errors before moving forward."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to run a cell\n",
    "- Click the ▶️ button on the left of a cell, or press **Shift+Enter** (Colab) / **Ctrl+Enter** (Kaggle).\n",
    "- A cell is done when a number like `[1]` appears on the left.\n",
    "- Do not skip steps; later cells rely on earlier setup."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 0 — Confirm the GPU is ready\n",
    "Run the next cell. You should see GPU name + memory. If you see `nvidia-smi unavailable`, switch the runtime to GPU and rerun this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi || echo \"nvidia-smi unavailable (CPU runtime)\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 — Point the notebook at the project folder\n",
    "This cell switches into the `ts-project` directory.\n",
    "If you get a `FileNotFoundError`, confirm where you uploaded/cloned the folder, adjust the path, and rerun."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "PROJECT_ROOT = Path.cwd().resolve()\n",
    "if PROJECT_ROOT.name == \"notebooks\":\n",
    "    PROJECT_ROOT = PROJECT_ROOT.parent.resolve()\n",
    "elif PROJECT_ROOT.name == \"content\":\n",
    "    candidate = PROJECT_ROOT / \"ts-project\"\n",
    "    if candidate.exists():\n",
    "        PROJECT_ROOT = candidate.resolve()\n",
    "\n",
    "if not (PROJECT_ROOT / \"src\").exists():\n",
    "    raise FileNotFoundError(\n",
    "        f\"Could not locate project root at {PROJECT_ROOT}. Upload or clone ts-project before proceeding.\"\n",
    "    )\n",
    "\n",
    "os.chdir(PROJECT_ROOT)\n",
    "if str(PROJECT_ROOT / \"src\") not in sys.path:\n",
    "    sys.path.append(str(PROJECT_ROOT / \"src\"))\n",
    "print(f\"Project root: {PROJECT_ROOT}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 — Install the project requirements\n",
    "Installs PyTorch + supporting libraries from `requirements.txt`. Expect quite a bit of output. If the install fails, rerun the cell before continuing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install project dependencies listed in requirements.txt\n",
    "!pip install -r requirements.txt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 — Run the smoke test\n",
    "This loads the dataset defined in your config, runs one optimizer step, and writes `outputs/smoke_metrics.json`.\n",
    "If the CSV specified in the config is missing, the cell will raise a clear error so you can add a sample dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import smoke_check\n",
    "\n",
    "smoke_path = smoke_check.run_smoke(\"configs/reg_tabular_mlp.yaml\")\n",
    "print(smoke_path.read_text())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Review smoke-test output\n",
    "- Confirm the previous cell printed a JSON block with the loss, batch size, and input shape.\n",
    "- `outputs/smoke_metrics.json` should now exist. If the smoke test failed because data is missing, create a small CSV and rerun it before proceeding.\n",
    "- Ready for full training? Continue to Section 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Full training run (optional)\n",
    "Train/evaluate on the configuration you choose. Default `reg_tabular_mlp.yaml` expects a CSV at `data/train.csv` with a numeric `target` column.\n",
    "\n",
    "**Before running:**\n",
    "1. Ensure your CSV paths in the config exist (or switch configs to the time-series variant).\n",
    "2. Open the config if you want to tweak epochs, batch size, learning rate, etc.\n",
    "3. Confirm the runtime still shows a GPU connection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model defined in configs/reg_tabular_mlp.yaml (tabular regression).\n",
    "!python src/train.py --config configs/reg_tabular_mlp.yaml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the saved checkpoint on the validation/test splits.\n",
    "!python src/evaluate.py --config configs/reg_tabular_mlp.yaml --ckpt outputs/best.pt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4 — What should I see now?\n",
    "- `outputs/best.pt`: trained weights + scaler metadata.\n",
    "- `outputs/log.csv`: epoch-by-epoch loss and regression metrics.\n",
    "- `outputs/metrics.json`: best validation MSE.\n",
    "- `outputs/eval.json`: validation (and, if configured, test) MSE/MAE/R².\n",
    "If any files are missing, scroll up for errors in the training/evaluation cells."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Switch configurations\n",
    "- To run the time-series variant, swap the config paths in the training/evaluation cells for `configs/reg_timeseries_lstm.yaml`.\n",
    "- Update the CSV paths (`data.csv_path`) to point at your series file (must include a timestamp column).\n",
    "- Re-run the smoke test and full run to validate the new setup.\n",
    "\n",
    "Keep the same order—GPU check → install → smoke test → train → evaluate—for consistent results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
