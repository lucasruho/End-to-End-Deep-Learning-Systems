{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP Starter — Colab/Kaggle Quickstart\n",
    "\n",
    "> Author : Badr TAJINI\n",
    "\n",
    "**Academic year:** 2025–2026  \n",
    "**School:** ECE  \n",
    "**Course:** Machine Learning & Deep Learning 2 \n",
    "\n",
    "---\n",
    "\n",
    "Welcome! This notebook walks you through the AG News text-classification starter on a free GPU runtime. Follow the steps in order to check the environment, install dependencies, and optionally train/evaluate the LSTM model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Project files\n",
    "\n",
    "- Option A: `git clone <your_repo_url> nlp-project`\n",
    "- Option B: Upload the `nlp-project` folder via the sidebar (it should appear as `/content/nlp-project` in Colab).\n",
    "\n",
    "Run the next cells afterward; they will raise helpful errors if the folder is missing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick checklist before running code\n",
    "- Switch the runtime to **GPU (T4)** first.\n",
    "  - Colab: `Runtime → Change runtime type → GPU → Save`.\n",
    "  - Kaggle: gear icon → enable **Accelerator**, choose `T4 x1`.\n",
    "- Wait for the runtime to reconnect.\n",
    "- Run each cell from top to bottom. If a cell errors, fix the issue, then rerun that same cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to run a cell\n",
    "- Click the ▶️ button on the left of a cell, or press **Shift+Enter** (Colab) / **Ctrl+Enter** (Kaggle).\n",
    "- A cell is finished when a number like `[1]` appears on the left.\n",
    "- Do not skip cells; the later ones depend on the setup above them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 0 — Confirm the GPU is ready\n",
    "Run the next cell. You should see a table with GPU details (name + memory). If you see `nvidia-smi unavailable`, the runtime is still on CPU—go back and switch it to GPU, then rerun this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi || echo \"nvidia-smi unavailable (CPU runtime)\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 — Point the notebook at the project folder\n",
    "This cell makes sure the notebook is executing inside the `nlp-project` directory.\n",
    "If it raises a `FileNotFoundError`, double-check where you uploaded/cloned the folder, adjust the path, and rerun."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "PROJECT_ROOT = Path.cwd().resolve()\n",
    "if PROJECT_ROOT.name == \"notebooks\":\n",
    "    PROJECT_ROOT = PROJECT_ROOT.parent.resolve()\n",
    "elif PROJECT_ROOT.name == \"content\":\n",
    "    candidate = PROJECT_ROOT / \"nlp-project\"\n",
    "    if candidate.exists():\n",
    "        PROJECT_ROOT = candidate.resolve()\n",
    "\n",
    "if not (PROJECT_ROOT / \"src\").exists():\n",
    "    raise FileNotFoundError(\n",
    "        f\"Could not locate project root at {PROJECT_ROOT}. Upload or clone nlp-project before proceeding.\"\n",
    "    )\n",
    "\n",
    "os.chdir(PROJECT_ROOT)\n",
    "if str(PROJECT_ROOT / \"src\") not in sys.path:\n",
    "    sys.path.append(str(PROJECT_ROOT / \"src\"))\n",
    "print(f\"Project root: {PROJECT_ROOT}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 — Install the project requirements\n",
    "This command reads `requirements.txt` and installs the exact package versions used locally. Expect a lot of output; that's normal. If installation fails, run the cell again before moving on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install project dependencies listed in requirements.txt\n",
    "!pip install -r requirements.txt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 — Run the smoke test\n",
    "This quick check downloads AG News (first run only), builds the vocabulary, and runs one mini-batch through the LSTM. It saves `outputs/smoke_metrics.json` so you know the pipeline works.\n",
    "If the cell reports a network/download issue, wait a few seconds and rerun it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import smoke_check\n",
    "\n",
    "smoke_path = smoke_check.run_smoke(\"configs/nlp_agnews.yaml\")\n",
    "print(smoke_path.read_text())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Review smoke-test output\n",
    "- Confirm the previous cell printed a JSON block (loss, batch size, seq_len).\n",
    "- You should now see `outputs/smoke_metrics.json` in the file browser on the left.\n",
    "- Only need a quick check? You can stop here. Ready for full training? Continue to Section 2.\n",
    "- If anything failed, read the error message, fix the issue, and rerun the smoke cell before moving on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Full training run (optional)\n",
    "Only run these cells when you want the complete experiment. On the first run, downloading the dataset and building the vocab may take a couple of minutes.\n",
    "\n",
    "**Before running:**\n",
    "1. Open `configs/nlp_agnews.yaml` (File → Open) if you want to tweak hyperparameters (epochs, learning rate, etc.).\n",
    "2. Ensure the runtime still shows a GPU connection.\n",
    "3. Close other heavy browser tabs to free memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model using the main configuration file. Expect visible progress bars.\n",
    "# The first epochs may start slowly while the dataset finishes downloading.\n",
    "!python src/train.py --config configs/nlp_agnews.yaml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the best checkpoint produced during training.\n",
    "# This prints validation/test metrics and writes eval.json to the outputs folder.\n",
    "!python src/evaluate.py --config configs/nlp_agnews.yaml --ckpt outputs/best.pt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4 — What should I see now?\n",
    "- `outputs/best.pt`: saved checkpoint with the trained weights and vocabulary.\n",
    "- `outputs/log.csv`: training history (loss/accuracy/F1 per epoch).\n",
    "- `outputs/metrics.json`: summary of the best validation F1.\n",
    "- `outputs/eval.json`: validation (and test, if available) accuracy/F1.\n",
    "If any of these files are missing, scroll up to check for errors in the training/evaluation cells."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Mirror this workflow for other runs\n",
    "1. Duplicate this notebook and rename it for your custom dataset (e.g., `01_custom_dataset.ipynb`).\n",
    "2. Edit the install cell if you add new packages to `requirements.txt`.\n",
    "3. Replace the config path with your own YAML file (CSV dataset, different splits, etc.).\n",
    "4. Use `python src/predict.py --ckpt outputs/best.pt --texts texts.json` to score custom sentences once training finishes.\n",
    "\n",
    "Following the same structure—GPU check → install → smoke test → full run—keeps your experiments tidy and reproducible."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
